## 第三章：貝葉斯統計

## 引言
貝葉斯統計（Bayesian statistics）是統計學的一個分支，在機器學習、人工智慧中扮演了至關重要的角色。相對於傳統的頻率派統計，貝葉斯統計更加關注如何通過數據更新先驗知識。它基於貝葉斯定理，用數據來更新具有不確定性的某個事件的概率分佈。貝葉斯推論可以用於許多領域，如機器學習、人工智慧、醫學、生物信息等等。

在本文中，我將使用 Python 語言，通過實際例子按步驟介紹貝葉斯統計的概念，包括貝葉斯定理、機率分佈、貝葉斯推斷和馬爾可夫鏈蒙特卡羅等重要概念。

## 貝葉斯定理
貝葉斯定理是貝葉斯統計的基礎，是條用於計算`先驗概率`和`後驗概率`的定理。其中，`先驗概率`是在觀測到數據之前對概率分佈的預測，而`後驗概率`是在觀測到數據後重新考慮概率分佈後的概率。

貝葉斯定理的數學表達式如下：

$$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$

其中， $A$ 和 $B$ 是兩個隨機事件， $P(A|B)$ 表示在已知發生 $B$ 的情況下， $A$ 發生的條件概率， $P(B|A)$ 表示在已知 $A$ 發生的情況下， $B$ 發生的條件概率， $P(A)$ 和 $P(B)$ 分別是 $A$ 和 $B$ 的先驗概率。 

簡單來說，貝葉斯定理是將先驗概率和觀測數據進行結合以得到後驗概率的公式。以下是一個直觀的例子：

一個病人做了某種疾病的檢測，假設已知此疾病在人群中的發病率為 $P(D)$，檢測的準確率是 $P(T|D)$ 表示當疾病存在時檢測呈陽性的概率， $P(T|\neg D)$ 則表示當疾病不存在時檢測呈陽性的概率。則病人在檢測呈陽性的情況下存在此疾病的概率為：

$$P(D|T)=\frac{P(T|D) P(D)}{P(T)}$$

其中 $P(T)=P(T|D) P(D)+P(T|\neg D) P(\neg D)$，計算結果就是得到病人存在此疾病的後驗概率。

## 機率分佈
在貝葉斯統計中，機率分佈是一個非常重要的概念，它描述變量的可能值及其對應的概率。不同的變量類型將有不同的機率分佈，例如貝努利分佈、二項分佈、正態分佈等等。

在 Python 中，我們可以使用 SciPy 庫中的 stats 模塊來實現常見機率分佈的計算。例如，我們想要計算正態分佈 $N(0,1)$ 中 $x=1$ 的概率分佈，代碼如下：

```
from scipy import stats

stats.norm(0, 1).pdf(1)
```

其中，`stats.norm(0, 1)` 創建了平均值為0，標準差為1的正態分佈對象，而 `pdf` 方法則返回變量為 $x$ 時的概率密度函數值。

相類似的，我們可以使用 `cdf` 方法來計算 $X < 1$ 的概率為多少。

```
stats.norm(0, 1).cdf(1)
```

## 貝葉斯推斷
貝葉斯統計最重要的應用之一就是通過數據進行推斷，也就是根據觀察到的數據更新我們對某些未知量的概率分佈。

貝葉斯推斷的基本步驟：

1. 定義未知量和似然函數；
2. 通過貝葉斯定理計算後驗分佈；
3. 檢查結果是否合理。

貝葉斯推斷的目的是使用先前的知識，提取新的知識。為了說明這一點，這裡舉個例子：

假設你正在玩一個掷骰子的遊戲，有未知的掷骰子面數 $k$ 需要確定。為了推斷 $k$ 的值，你進行了 $n$ 次掷骰子，得到了一些觀察到的數據 $x_1, x_2, ..., x_n$，並且在進行掷骰子之前，你對 $k$ 的分布有一些先驗知識。現在，如何通過這些數據更新 $k$ 的分布呢？

貝葉斯推斷就是用來解決這個問題的。下面是貝葉斯推斷的 Python 代碼實現：

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# 定義分佈的先驗
k_vals = np.arange(1, 50)
prior = np.ones_like(k_vals, dtype=np.float64)

# 定義似然函數
def likelihood(data, k):
    if np.any(data < 1) or np.any(data > k):
        return 0.0
    else:
        return 1.0 / k ** len(data)

# 定義後驗分佈的計算函數
def posterior(data, prior, k_vals):
    unnormal_posterior = [prior[i] * likelihood(data, k_vals[i]) for i in range(len(k_vals))]
    normal_constant = sum(unnormal_posterior)
    return [posterior / normal_constant for posterior in unnormal_posterior]

# 生成觀察數據
data = np.array([10, 20, 30])

# 計算後驗分佈
post = posterior(data, prior, k_vals)

# 可視化結果
fig, ax = plt.subplots(figsize=(12, 6))

ax.plot(k_vals, post, 'o-', label='k posterior')
ax.set_xlabel('k')
ax.set_ylabel('posterior probability')
ax.set_title(f'Data: {data}')
ax.legend(loc=0)
```

在代碼中，我們將 $k$ 的取值範圍定義在 $[1,50]$ 之間，同時將 $k$ 的先驗分佈定義為一個均勻分布。然後我們定義了目標函數 likelihood(data, k)，用來計算給定數據 $data$ 時，參數 $k$ 的概率。在後面的 posterior 函數中，我們通過貝葉斯定理計算出參數 $k$ 的後驗概率，並最終可視化結果。

## 馬爾可夫鏈蒙特卡羅
在實際應用中，通常一些模型很複雜，或目標函數梯度很難求解，或數據量太大。這種情況下，一般的最小二乘等算法就會失灵，這時可以使用 MCMC（Markov Chain Monte Carlo）方法。

首先，我們來看看什麼是馬爾可夫鏈。一個馬爾科夫鏈是一個隨機過程，其中下一個狀態只取決於當前狀態，而且距離當前狀態越遠，條件概率分佈也就越多地接近整個分配。

在貝葉斯推斷中，我們需要根據後驗概率分布生成樣本，並使用這些樣本估算後驗分布的期望和方差等重要參數。而 MCMC 正是一種用於產生隨機樣本的方法，其中 Metropolis 算法是其中最常見的一種。

下面是 Metropolis-Hastings 算法的 Python 代碼實現：

```python
from scipy.stats import norm

def normal(x, mu, sigma):
    return norm.pdf(x, mu, sigma)

def metropolis_hastings(p, step_size=0.1, n_iters=1000):
    x = 0.0
    samples = [x]
    for i in range(n_iters):
        x_star = x + np.random.normal(0, step_size)
        p_star = p(x_star)
        p_x = p(x)
        acceptance = min(1.0, p_star / p_x)
        accept = np.random.uniform(0, 1) < acceptance
        if accept:
            x = x_star
        samples.append(x)
    return np.array(samples)
```

Metropolis-Hastings 算法的基本思想是通過某種方法產生一些候選樣本，並根據某種準則進行接受或拒絕。在上面的代碼中，我們實現的是一個以0為中心、0.5為標準差的正態分佈，使用的是步長為0.1、迭代次數為1000的 Metropolis-Hastings 算法。通過這個算法，我們可以得到符合目標分佈的樣本。

下面是使用 Metropolis-Hastings 算法獲取正態分佈的均值和方差的 Python 代碼：

```python
p = lambda x: normal(x, mu=4, sigma=1) * normal(x**2, mu=6, sigma=1)

samples = metropolis_hastings(p, step_size=0.1, n_iters=10000)
burnin = 1000
trimmed = samples[burnin:]

print(f'mean: {trimmed.mean()}, std: {trimmed.std()}')
```

在上述代碼中，我們使用了一個複雜的雙峰分佈作為目標函數（兩個正態分佈的乘積）。然後，我們使用 Metropolis-Hastings 算法獲取樣本，通過篩選掉之前的 1000 條樣本，然後估算正態分佈的期望和方差。