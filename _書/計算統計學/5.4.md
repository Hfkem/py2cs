## 5.4 混合高斯模型的 EM 算法

混合高斯模型是一個利用多個高斯分布組合成一個模型的統計模型。它通常用於對複雜的數據樣本進行建模和分析。在混合高斯模型中，每個高斯分布的權重和參數都需要被學習。EM 算法可用於學習混合高斯模型的參數。

EM 算法的全稱是期望最大化算法（Expectation Maximization Algorithm）。在混合高斯模型中，EM 算法需要隨機初始化參數，之後通過以下步驟不斷更新參數：

E 步驟（Expectation step）：給定參數，計算出每個數據點屬於每個高斯分布的概率。

M 步驟（Maximization step）：使用 E 步驟計算出的概率，更新高斯分布的權重、均值和方差參數。 

EM 算法重複執行 E 步驟和 M 步驟，直到收斂。 在混合高斯模型中，EM 算法的 E 步驟和 M 步驟具體如下：

E 步驟：

對每個數據 $x_i$ 和每個高斯分布 $j$，計算 $x_i$屬於高斯分布 $j$ 的概率：

$$
    w_{ij} = \frac{N(x_i|\mu_j,\Sigma_j)p_j}{\sum_{k=1}^K N(x_i|\mu_k,\Sigma_k)p_k}
$$

其中， $N(x_i|\mu_j,\Sigma_j)$代表高斯分布， $\mu_j$ 代表均值， $\Sigma_j$ 代表協方差。$p_j$ 是高斯分布的權重， $K$ 是高斯分布的數量。

M 步驟：

對每個高斯分布 $j$，將數據點 $x_i$ 的權重加總得到 $j$ 的權重 $p_j$：

$$
    p_j = \frac{\sum_{i=1}^N w_{ij}}{N}
$$

對每個高斯分布 $j$，計算出 $j$ 的均值和協方差：

$$
    \mu_j = \frac{\sum_{i=1}^N w_{ij}x_i}{\sum_{i=1}^N w_{ij}}
$$

$$
    \Sigma_j = \frac{\sum_{i=1}^N w_{ij}(x_i-\mu_j)(x_i-\mu_j)^T}{\sum_{i=1}^N w_{ij}}
$$

混合高斯模型的 EM 算法是一個迭代過程，可以通過設置閾值或最大迭代次數來決定算法的停止條件。混合高斯模型是一個有效的統計模型，可用於多個領域，如模式識別、計算機視覺和數據壓縮等。