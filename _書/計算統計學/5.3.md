## 5.3 隱性馬爾可夫模型的 EM 算法

本節介紹隱性馬爾可夫模型（Hidden Markov Model, HMM）的參數學習方法：期望最大化（Expectation-Maximization, EM）算法，旨在通過觀測序列和條件概率求解模型參數。

### 5.3.1 EM 算法簡介

期望最大化算法，簡稱 EM 算法，是一種通用的參數估計方法，主要用於隱性模型的參數估計。

EM 算法包含兩大步驟：

Expectation（E）步：計算觀測序列中隱性變量的期望值;

Maximization（M）步：最大化對數概率，從而計算模型參數。

EM 算法屬於迭代算法，從初始值開始，反覆執行 E 步和 M 步，直到收斂為止。

### 5.3.2 HMM 的 EM 算法

HMM 包含兩個隱性變量：隱性狀態序列和觀測序列。因此，在 HMM 的參數學習過程中，需要計算每個時間步的條件概率及其期望值。

當確定了隱性狀態序列和觀測序列時，可以通過前向算法或後向算法求解，這些算法將在 5.4 小節中進行介紹。

在 HMM 的 EM 算法中，可以獲得以下模型參數：

1. 初始概率：$\pi_i=P(q_1=s_i)$，表示在時間步1隱性狀態為 $s_i$ 的概率；

2. 狀態轉移概率：$a_{ij}=P(q_t=s_j|q_{t-1}=s_i)$，表示在時間步 $t-1$ 隱性狀態為 $s_i$，時間步隱性狀態為 $s_j$ 的概率；

3. 觀測概率：$b_i(k)=P(o_t=v_k|q_t=s_i)$，表示在隱性狀態為 $s_i$ 時，觀測到 $v_k$ 的概率。

在 HMM 中，觀測序列和隱性狀態序列均未知。因此，EM 算法需要通過期望值來計算這些未知變量，進而求解參數。

### 5.3.3 HMM 的 E 步

在 HMM 的 E 步中，需要計算給定模型參數下，觀測序列 $O$ 上每個隱性狀態出現的期望值。

令 $\boldsymbol{\alpha}_t=(\alpha_t(1), \alpha_t(2), ..., \alpha_t(N))^T$ 表示在時間步 $t$ 隱性狀態為 $s_i$ 的概率，且觀測到 $O_t$ 的序列的條件概率，其中 $N$ 為隱性狀態的總數。則有：

$$\alpha_t(i)=P(O_1, O_2, ..., O_t, q_t=s_i|\lambda)$$

其中， $\lambda=(\boldsymbol{\pi}, \boldsymbol{A}, \boldsymbol{B})$ 表示 HMM 的參數。

因此，可以表示為以下公式：

$$\alpha_1(i)=\pi_i b_i(o_1)$$

$$\alpha_t(i)=\left(\sum^{N}_{j=1}\alpha_{t-1}(j)a_{ji}\right)b_i(O_t), t=2,3,...,T$$

利用前向算法可以快速計算 $\boldsymbol{\alpha}_t$ 的值。在此基礎上，可以求出給定觀測序列的隱性狀態序列概率：

$$\gamma_t(i)=P(q_t=s_i|O, \lambda)=\frac{\alpha_t(i)\beta_t(i)}{P(O|\lambda)}$$

其中， $\beta_t(i)=P(O_{t+1}, O_{t+2}, ..., O_T|q_t=s_i,\lambda)$，可以利用後向算法計算得到， $\beta$ 函數與 $\alpha$ 函數非常相似，只是在逆向計算的過程中，需要用遞迴方式來計算。

因此，可以建立 E 步中的期望值表示式：

$$\begin{aligned} \xi_t(i,j)&=P(q_t=s_i, q_{t+1}=s_j|O, \lambda) \\ &=\frac{P(q_t=s_i, q_{t+1}=s_j, O|\lambda)}{P(O|\lambda)} \\ &={\frac{\alpha_t(i)a_{ij}b_j(O_{t+1})\beta_{t+1}(j)}{P(O|\lambda)}} \\ &={\frac{\alpha_t(i)a_{ij}b_j(O_{t+1})\beta_{t+1}(j)\gamma_t(i)}{\gamma_t(i)}} \\ &=\frac{\alpha_t(i)a_{ij}b_j(O_{t+1})\beta_{t+1}(j)}{\sum_{i=1}^N\alpha_t(i)a_{ij}b_j(O_{t+1})\beta_{t+1}(j)} \end{aligned}$$

因此，隱含在每個時間步之間的隱性變量的條件概率期望值為：

$$\begin{aligned} \gamma_t(i)&=\sum_{j=1}^N\xi_t(i,j) \\ &=\frac{\alpha_t(i)\beta_t(i)}{P(O|\lambda)} \\ &=\alpha_t(i)\beta_t(i)\sum_{j=1}^N\frac{a_{ij}b_j(O_{t+1})}{\sum_{k=1}^N\alpha_t(k)a_{kj}b_j(O_{t+1})\beta_{t+1}(j)} \end{aligned}$$

根據期望最大化算法的 E 步，對於觀測序列 $O$，逐個時間步推算隱性狀態的期望值 $\gamma_t(i)$ 和隱性狀態轉移的期望值 $\xi_t(i,j)$。

### 5.3.4 HMM 的 M 步

在 HMM 的 M 步中，需要最大化 E 步中的期望值，從而獲得新的參數。

首先，更新初始概率：

$$\pi_i^{new}= \gamma_1(i)$$

然後，更新狀態轉移概率 $a_{ij}$：

$$a_{ij}^{new}=\frac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1}\gamma_t(i)}$$

最後，更新觀測概率 $b_i(k)$：

$$b_i^{new}(k)=\frac{\sum_{t=1,o_t=v_k}^{T}\gamma_t(i)}{\sum_{t=1}^T\gamma_t(i)}$$

通過 E 步和 M 步交替迭代，可以獲得新的模型參數，由於 EM 算法的收斂速度較慢，因此通常需要設定固定的迭代次數或者設定收斂條件來確定算法結束。

### 5.3.5 HMM 的參數學習

將 E 步和 M 步聯合起來，可以得到 HMM 訓練的 EM 算法。

基本步驟如下：

1. 初始化 HMM 的參數 $\lambda=(\boldsymbol{\pi}, \boldsymbol{A}, \boldsymbol{B})$，可以隨機初始化；

2. 進行 E 步，計算每個時間步的條件概率 $\gamma_t(i)$ 和期望值 $\xi_t(i,j)$；

3. 進行 M 步，通過期望最大化更新模型參數；

4. 重複執行步驟 2 和步驟 3，直到收斂。

HMM 的參數學習可以利用 Python 中的 hmmlearn 模塊實現，其中，EM 算法可以通過 hmmlearn 包中的 `hmm.GaussianHMM`， `hmm.MultinomialHMM`，`hmm.GMMHMM` 等類實現。可以通過設置參數，指定狀態數、觀測概率分布類型、狀態轉移矩陣等。

HMM 的參數學習過程非常耗時，因此，在實際應用中，通常需要進行降維處理，以縮短模型所需的訓練時間。
