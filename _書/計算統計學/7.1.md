## 7.1 Metropolis-Hastings算法

Metropolis-Hastings算法是一種基於馬爾可夫鏈蒙特卡羅(MCMC)的抽樣方法，它基於的核心思想是通過一個提案分布和一個接受機制，在一個高維空間中作抽樣。

Metropolis-Hastings算法的步驟如下：

1. 當前狀態為 $x^{(t)}$，根據提案分布 $q(y|x^{(t)})$ 得到候選狀態 $y$；
2. 計算接受率 $\alpha = \min\left(1, \frac{p(y)}{p(x^{(t)})} \cdot \frac{q(x^{(t)}|y)}{q(y|x^{(t)})}\right)$；
3. 用一個均勻分布 $U$ 從 $[0,1]$ 中抽一個值 $u$;
4. 如果 $u \leq \alpha$，則接受由 $x^{(t)}$ 轉移到 $y$ 的轉移，即 $x^{(t+1)}=y$，否則拒絕該轉移，即 $x^{(t+1)}=x^{(t)}$。

其中 $p(x)$ 是狀態 $x$ 的目標概率分布，$q(y|x)$ 是從狀態 $x$ 到候選狀態 $y$ 的提案分布，$q(x|y)$ 是從候選狀態 $y$ 到狀態 $x$ 的提案分布。

Metropolis-Hastings算法是一種可適用於各種複雜分布的抽樣方法，但是選擇合適的提案分布和設置良好的參數比較困難。因此，在實際應用中需要對其進行充分的評估與調試。

下面我們將使用Python實現Metropolis-Hastings算法來進行抽樣。## 7.1 Metropolis-Hastings算法

Metropolis-Hastings（M-H）算法是一種Markov Chain Monte Carlo（MCMC）方法，用於模擬從一個隨機分佈中抽取樣本的過程。在實際應用中，常常出現一些複雜的概率分佈，它們不容易直接抽樣，但可以從另一個容易抽樣的概率分佈中獲得抽樣。M-H算法就是用一個轉移核函数將一個容易抽樣的概率分佈轉移到一個複雜的概率分佈上，從而實現從複雜概率分佈中抽樣。

假設我們要從一個概率密度函數 $f(x)$ 中抽樣，但是無法直接計算 $f(x)$ 的概率密度函數，但可以從另外一個參數為 $\mu$ 且容易抽樣的概率密度函數 $g(x|\mu)$ 中抽樣，那麼我們可以按照以下步驟進行：

1. 從 $g(x_{t+1}|\mu)$ 中生成一個對稱提議，即 $x_{t+1}=y$，其中 $y$ 為從 $g(x_t|\mu)$ 抽出的一個樣本；
2. 計算接受率，即：$$\alpha(x_t,y) = min\left\{1,\frac{f(y)}{f(x_t)}\right\}$$
3. 以概率 $\alpha(x_t,y)$ 接受提議，即：
	- 如果接受，則 $x_{t+1}=y$；
	- 如果不接受，則 $x_{t+1}=x_t$。

重複上述步驟 $T$ 次，則得到一個長度為 $T$ 的 MCMC 樣本序列 $x_1,x_2,...,x_T$。當 $T$ 足夠大時，可以證明這個序列是收斂到 $f(x)$ 的平穩態的，也就是說，使用 M-H 算法可以從一個容易抽樣的概率分佈轉移到另一個複雜的概率分佈上。

在具體實現中，可以選擇不同的 $g(x|\mu)$ 函数。常見的幾種選擇包括高斯分佈、均勻分佈、指數分佈等。實現時，需要根據具體情況選擇合適的 $g(x|\mu)$ 函数，使得接受率 $\alpha(x_t,y)$ 不太小，也不太大，一般應該在 0.2 和 0.5 之間。通常，可以使用試錯法和一些現成的實現工具包（如 PyMC）來選擇合適的參數。## 7.1 Metropolis-Hastings算法

Metropolis-Hastings算法是馬爾可夫鏈蒙特卡羅（MCMC）方法的一個重要應用，用於從概率分布中抽樣。當分布的正常化常數未知或難以求得時，MCMC方法尤其有用。這種方法在統計學、物理學、計算機科學和生物學等領域都被廣泛應用。

Metropolis-Hastings算法的基本思想是在一個馬爾可夫鏈上遍歷，並保證遍歷結果最終會收斂到目標分布。這個過程涉及到一個接受-拒絕策略，即對於當前的狀態，根據一定的機率從候選狀態的分布中選擇一個新的狀態，然後檢查這個新的狀態是否被接受。如果接受，則將其作為下一個狀態；如果拒絕，則當前狀態是下一個狀態。由於擁有自適應規則，此演算法能夠平滑解決「隨時間變化而改變形狀的目標分布」的問題，也就是隨著時間的推移，演算法生成的樣本能夠更好地符合概率分布。

以下是Metropolis-Hastings算法的基本步驟:

1. 選擇初始狀態 $x^{(0)}$和候選分布$q(x^{(t+1)}|x^{(t)})$
2. 對於t = 0, 1, 2,..., 生成序列$x^{(0)},x^{(1)},x^{(2)},...$:
	1. 從候選分布$q(x^{(t+1)}|x^{(t)})$中抽樣得到一個候選狀態$x_c^{(t+1)}$
	2. 計算接受概率:
		$$
		\alpha(x^{(t)},x_c^{(t+1)}) = min\left(1,\frac{\pi(x_c^{(t+1)})q(x^{(t)}|x_c^{(t+1)})}{\pi(x^{(t)})q(x_c^{(t+1)}|x^{(t)})}\right)
		$$
	3. 從均勻分布$U(0,1)$中抽樣得到一個隨機數$u$
	4. 如果$u\leq\alpha(x^{(t)},x_c^{(t+1)})$，則接受候選狀態$x_c^{(t+1)}$，即$x^{(t+1)}=x_c^{(t+1)}$；否則拒絕候選狀態，即$x^{(t+1)}=x^{(t)}$

這個演算法的關鍵是候選分布$q(x^{(t+1)}|x^{(t)})$的選擇。在實際應用中，可以選擇一些簡單的分布，例如高斯分布。當候選分布的方差越大時，接受率就越低，這會降低鍊的自相關，從而提高估計的精度。此外，如果目標分布很吸收，則選擇小方差的候選分布也會提高接受率。

Metropolis-Hastings算法收斂到目標分布的關鍵是選擇正確的接受概率。當接受概率接近1時，鍊會平穩地在目標分布上遊走，否則鍊的自相關將增加，從而降低估計的精度。
