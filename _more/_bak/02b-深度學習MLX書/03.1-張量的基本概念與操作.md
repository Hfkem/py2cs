### **張量的基本概念與操作**

張量（Tensor）是機器學習和深度學習的核心數據結構之一。MLX 框架提供高效的張量運算功能，並充分發揮 **Apple Silicon** 的運算性能，使張量操作快速而直觀。本節將介紹張量的基本概念、常見操作及 MLX 中的具體實現方法。

---

### **1. 張量的基本概念**

張量可以被視為多維的數據結構，是向量和矩陣的擴展形式：

- **標量（0階張量）**：單個數值，例如：`5`。
- **向量（1階張量）**：一維數組，例如：`[1, 2, 3]`。
- **矩陣（2階張量）**：二維數組，例如：
  ```
  [[1, 2, 3],
   [4, 5, 6]]
  ```
- **高階張量（3階及以上）**：多維數組，例如影像數據（3D 張量）或批量數據（4D 張量）。

---

### **2. 創建張量**

在 MLX 中，張量可以通過各種方式創建，例如從列表、數組或初始化函數。

#### **2.1 從列表創建張量**

使用 `mlx.core` 中的 `mx.array()` 方法：

```python
import mlx.core as mx

# 創建一個一維張量（向量）
tensor_1d = mx.array([1, 2, 3])
print(tensor_1d)

# 創建一個二維張量（矩陣）
tensor_2d = mx.array([[1, 2, 3], [4, 5, 6]])
print(tensor_2d)
```

#### **2.2 初始化特殊張量**

MLX 提供一些便利函數用於初始化特殊形狀的張量：

```python
# 全零張量
zeros = mx.zeros((2, 3))
print("Zeros Tensor:\n", zeros)

# 全一張量
ones = mx.ones((2, 3))
print("Ones Tensor:\n", ones)

# 隨機張量
random_tensor = mx.random.uniform(shape=(2, 3))
print("Random Tensor:\n", random_tensor)
```

---

### **3. 張量的屬性**

張量具有一些重要的屬性，可以幫助您瞭解張量的結構與內容：

```python
tensor = mx.array([[1, 2, 3], [4, 5, 6]])

# 張量的形狀（Shape）
print("Shape:", tensor.shape)  # (2, 3)

# 張量的維度數（Rank）
print("Rank:", len(tensor.shape))  # 2

# 張量的數據類型（Data Type）
print("Data Type:", tensor.dtype)  # float32（默認）
```

---

### **4. 張量的常見操作**

MLX 提供豐富的張量運算 API，以下是常見操作的示例：

#### **4.1 基本算術操作**

張量支援加、減、乘、除等元素級操作：

```python
a = mx.array([[1, 2], [3, 4]])
b = mx.array([[5, 6], [7, 8]])

# 加法
add_result = a + b
print("Add:\n", add_result)

# 減法
sub_result = a - b
print("Subtract:\n", sub_result)

# 乘法（逐元素）
mul_result = a * b
print("Multiply:\n", mul_result)

# 除法（逐元素）
div_result = a / b
print("Divide:\n", div_result)
```

#### **4.2 張量維度操作**

可以調整張量的形狀或維度，例如 `reshape`、`transpose` 等：

```python
tensor = mx.array([[1, 2, 3], [4, 5, 6]])

# 重塑張量
reshaped_tensor = mx.reshape(tensor, (3, 2))
print("Reshaped Tensor:\n", reshaped_tensor)

# 轉置張量
transposed_tensor = mx.transpose(tensor)
print("Transposed Tensor:\n", transposed_tensor)
```

#### **4.3 總和與均值操作**

MLX 支援沿特定維度進行求和或均值計算：

```python
tensor = mx.array([[1, 2, 3], [4, 5, 6]])

# 總和
sum_tensor = mx.sum(tensor)
print("Sum:", sum_tensor)

# 沿維度 0 求和（列求和）
sum_dim0 = mx.sum(tensor, axis=0)
print("Sum along axis 0:\n", sum_dim0)

# 平均值
mean_tensor = mx.mean(tensor)
print("Mean:", mean_tensor)
```

#### **4.4 範數與其他數學操作**

```python
# L2 範數
l2_norm = mx.norm(tensor)
print("L2 Norm:", l2_norm)

# 指數與對數操作
exp_tensor = mx.exp(tensor)
print("Exponential:\n", exp_tensor)

log_tensor = mx.log(tensor)
print("Logarithm:\n", log_tensor)
```

---

### **5. 張量與 Numpy 的互操作**

MLX 張量可以方便地與 Numpy 數據結構互相轉換：

```python
import numpy as np

# Numpy 轉 MLX 張量
np_array = np.array([[1, 2], [3, 4]])
mlx_tensor = mx.array(np_array)
print("MLX Tensor:\n", mlx_tensor)

# MLX 張量轉 Numpy
converted_np_array = mlx_tensor.numpy()
print("Numpy Array:\n", converted_np_array)
```

---

### **6. 高性能張量運算**

MLX 對 Apple Silicon 的 **GPU** 和 **加速器** 進行了優化，能夠在大規模數據上高效運行：

- 自動調度運算到最佳硬件（CPU/GPU）。
- 支援張量並行運算，減少運行時間。

**示例**：大量隨機數據進行加法運算：

```python
a = mx.random.uniform(shape=(1000, 1000))
b = mx.random.uniform(shape=(1000, 1000))

result = a + b
print("Computation Completed!")
```

---

### **7. 小結**

本節介紹了張量的基本概念、屬性和常見操作，並通過 MLX 提供的 API 演示了如何進行張量的創建、運算和維度變換。張量是深度學習的基石，熟練掌握張量操作將為您使用 MLX 架構神經網路打下堅實基礎。

接下來，我們將深入介紹 **MLX 的自動微分功能**，探討如何高效計算梯度並應用於模型訓練！