使用 **MLX** 框架來生成手寫數字圖像（MNIST）是 GAN 中的一個常見應用。這裡將介紹如何使用 GAN 模型生成手寫數字圖像。首先，我們將構建 GAN 的生成器和判別器，並使用 MNIST 數據集進行訓練。

### **1. 安裝與導入所需庫**

確保已經安裝了 MLX，並導入必要的庫。

```bash
pip install mlx torchvision matplotlib
```

### **2. 加載 MNIST 數據集**

我們使用 `torchvision` 來加載 MNIST 數據集，這是一個包含 28x28 像素手寫數字的數據集。

```python
import mlx
import mlx.nn as nn
import mlx.optim as optim
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# 加載 MNIST 數據集
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
data_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
```

### **3. 定義生成器與判別器**

GAN 由生成器和判別器組成，生成器負責生成假圖像，判別器負責判斷圖像的真假。

```python
# 生成器（Generator）
class Generator(nn.Module):
    def __init__(self, latent_dim):
        super(Generator, self).__init__()
        self.fc1 = nn.Linear(latent_dim, 256)
        self.fc2 = nn.Linear(256, 512)
        self.fc3 = nn.Linear(512, 1024)
        self.fc4 = nn.Linear(1024, 784)  # 28x28 的圖像展開為784維向量

    def forward(self, z):
        z = nn.ReLU()(self.fc1(z))
        z = nn.ReLU()(self.fc2(z))
        z = nn.ReLU()(self.fc3(z))
        return nn.Tanh()(self.fc4(z)).view(-1, 28, 28)  # 轉換為 28x28 圖像

# 判別器（Discriminator）
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.fc1 = nn.Linear(784, 1024)
        self.fc2 = nn.Linear(1024, 512)
        self.fc3 = nn.Linear(512, 256)
        self.fc4 = nn.Linear(256, 1)  # 輸出真假標籤

    def forward(self, x):
        x = nn.LeakyReLU(0.2)(self.fc1(x))
        x = nn.LeakyReLU(0.2)(self.fc2(x))
        x = nn.LeakyReLU(0.2)(self.fc3(x))
        return nn.Sigmoid()(self.fc4(x))  # 輸出 0 或 1 的真假標籤
```

### **4. 定義損失函數與優化器**

GAN 使用對抗損失來訓練生成器和判別器。

```python
# 損失函數：二元交叉熵
def binary_cross_entropy(output, target):
    return -(target * nn.LogSoftmax()(output) + (1 - target) * nn.LogSoftmax()(1 - output))

# 優化器
latent_dim = 100  # 隨機噪聲的維度
generator = Generator(latent_dim)
discriminator = Discriminator()

optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))
```

### **5. 訓練過程**

訓練過程包括訓練判別器和生成器。判別器學會區分真實的 MNIST 圖像和生成的假圖像，而生成器學會生成能夠欺騙判別器的假圖像。

```python
import matplotlib.pyplot as plt

# 訓練過程
epochs = 50
for epoch in range(epochs):
    for i, (real_images, _) in enumerate(data_loader):
        # 把圖像展開為 784 維的向量
        real_images = real_images.view(real_images.size(0), -1)
        batch_size = real_images.size(0)

        # 真實圖像的標籤為 1，假圖像的標籤為 0
        real_labels = torch.ones(batch_size, 1)
        fake_labels = torch.zeros(batch_size, 1)

        # 訓練判別器
        optimizer_D.zero_grad()

        # 訓練判別器對真實圖像
        output_real = discriminator(real_images)
        loss_real = binary_cross_entropy(output_real, real_labels)

        # 訓練判別器對假圖像
        noise = torch.randn(batch_size, latent_dim)  # 隨機噪聲
        fake_images = generator(noise).view(batch_size, -1)
        output_fake = discriminator(fake_images.detach())  # 不計算梯度
        loss_fake = binary_cross_entropy(output_fake, fake_labels)

        loss_D = loss_real + loss_fake
        loss_D.backward()
        optimizer_D.step()

        # 訓練生成器
        optimizer_G.zero_grad()
        output_fake = discriminator(fake_images)
        loss_G = binary_cross_entropy(output_fake, real_labels)  # 生成器的目標是讓判別器將假圖像判定為真

        loss_G.backward()
        optimizer_G.step()

    print(f"Epoch [{epoch}/{epochs}], Loss_D: {loss_D.item()}, Loss_G: {loss_G.item()}")

    # 每個 epoch 生成樣本並顯示
    if (epoch + 1) % 10 == 0:
        noise = torch.randn(16, latent_dim)
        generated_images = generator(noise).detach().numpy()

        fig, axes = plt.subplots(4, 4, figsize=(8, 8))
        for i, ax in enumerate(axes.flatten()):
            ax.imshow(generated_images[i], cmap='gray')
            ax.axis('off')
        plt.show()
```

### **6. 生成手寫數字圖像**

在訓練過程中，每個 `epoch` 結束時，我們生成並顯示一些由生成器生成的手寫數字圖像。這樣可以檢查生成器的效果，看看它是否學會生成真實的手寫數字。

```python
# 訓練完成後生成新圖像
noise = torch.randn(16, latent_dim)
generated_images = generator(noise).detach().numpy()

# 顯示生成的手寫數字
fig, axes = plt.subplots(4, 4, figsize=(8, 8))
for i, ax in enumerate(axes.flatten()):
    ax.imshow(generated_images[i], cmap='gray')
    ax.axis('off')
plt.show()
```

### **7. 結語**

這個例子展示了如何使用 **MLX** 框架來實現一個簡單的 GAN，並用它生成手寫數字圖像（MNIST）。通過對抗性訓練，生成器學會生成越來越真實的圖像，而判別器學會區分真實和偽造的圖像。隨著訓練的進行，生成器的生成效果會越來越好。

你可以根據需要進一步優化模型，比如使用卷積層來提升生成圖像的質量，或者調整超參數以加速訓練過程。