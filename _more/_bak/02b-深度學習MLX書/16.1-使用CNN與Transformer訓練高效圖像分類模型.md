### MLX: 使用 CNN 與 Transformer 訓練高效圖像分類模型

在這一節中，我們將展示如何使用 `MLX` 框架來構建一個高效的圖像分類模型，這個模型結合了卷積神經網絡（CNN）和 Transformer 模塊。這樣的結合可以讓我們充分發揮 CNN 的局部特徵學習能力與 Transformer 在捕捉全局依賴關係方面的優勢，從而提高圖像分類的準確性。

---

### 1. **模型設計：CNN 與 Transformer 結合**

我們將設計一個結合 CNN 和 Transformer 的混合架構，利用 CNN 層進行特徵提取，再利用 Transformer 層來學習圖像中的全局依賴。

#### CNN + Transformer 模型結構

```python
import mlx
import mlx.nn as nn
import mlx.optim as optim
from mlx import transforms
from torchvision import datasets

# 定義 CNN 模塊
class CNNModule(nn.Module):
    def __init__(self):
        super(CNNModule, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(128 * 8 * 8, 1024)
        self.fc2 = nn.Linear(1024, 256)

    def forward(self, x):
        x = self.pool(nn.ReLU()(self.conv1(x)))
        x = self.pool(nn.ReLU()(self.conv2(x)))
        x = x.view(x.size(0), -1)  # 展平成一維
        x = nn.ReLU()(self.fc1(x))
        x = nn.ReLU()(self.fc2(x))
        return x

# 定義 Transformer 模塊
class TransformerModule(nn.Module):
    def __init__(self, input_dim, num_classes):
        super(TransformerModule, self).__init__()
        self.attention = nn.MultiheadAttention(embed_dim=input_dim, num_heads=8)
        self.fc = nn.Linear(input_dim, num_classes)

    def forward(self, x):
        # 假設 x 的形狀是 (batch_size, seq_len, embedding_dim)
        x = x.unsqueeze(0)  # 增加一個維度，以適應多頭注意力的輸入格式
        attn_output, _ = self.attention(x, x, x)  # 多頭自注意力
        x = attn_output.squeeze(0)  # 刪除額外的維度
        x = self.fc(x)  # 最終的分類層
        return x

# 結合 CNN 和 Transformer 的混合模型
class CNN_Transformer_Model(nn.Module):
    def __init__(self, num_classes=10):
        super(CNN_Transformer_Model, self).__init__()
        self.cnn = CNNModule()  # CNN 層進行特徵提取
        self.transformer = TransformerModule(input_dim=256, num_classes=num_classes)  # Transformer 層

    def forward(self, x):
        x = self.cnn(x)  # CNN 層
        x = self.transformer(x)  # Transformer 層
        return x
```

- **CNNModule**：該模塊使用兩層卷積來提取圖像的局部特徵，並通過全連接層進行特徵融合。
- **TransformerModule**：在提取的特徵上使用 Transformer 來捕捉全局的依賴關係。
- **CNN_Transformer_Model**：結合 CNN 和 Transformer 模塊進行圖像分類。

---

### 2. **數據處理：數據增強與預處理**

我們將使用 CIFAR-10 數據集，並應用數據增強技術來提高模型的泛化能力。

```python
# 數據增強與預處理
transform = transforms.Compose([
    transforms.RandomResizedCrop(32),  # 隨機裁剪
    transforms.RandomHorizontalFlip(),  # 隨機翻轉
    transforms.ToTensor(),             # 轉換為張量
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 歸一化
])

# 加載 CIFAR-10 訓練數據集
train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
train_loader = mlx.utils.DataLoader(train_dataset, batch_size=64, shuffle=True)

# 加載測試數據集
test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
test_loader = mlx.utils.DataLoader(test_dataset, batch_size=64, shuffle=False)
```

---

### 3. **訓練過程**

在訓練過程中，我們使用 `Adam` 優化器和交叉熵損失函數來優化模型的權重。

```python
# 設置設備
device = mlx.device('cpu')  # 這裡可以選擇使用 'cpu' 或 'mps'（如果使用 Apple Silicon）

# 初始化模型、損失函數和優化器
model = CNN_Transformer_Model(num_classes=10).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 訓練過程
def train(model, train_loader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    return running_loss / len(train_loader), 100. * correct / total

# 執行訓練
for epoch in range(10):
    loss, accuracy = train(model, train_loader, criterion, optimizer, device)
    print(f'Epoch [{epoch+1}/10], Loss: {loss:.4f}, Accuracy: {accuracy:.2f}%')
```

---

### 4. **測試與評估**

在測試階段，我們將計算測試損失和準確率，來評估模型的表現。

```python
def test(model, test_loader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    with mlx.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss.item()

            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    return running_loss / len(test_loader), 100. * correct / total

# 測試模型
loss, accuracy = test(model, test_loader, criterion, device)
print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.2f}%')
```

---

### 5. **結論與優化**

這個結合 CNN 和 Transformer 的模型能夠有效地處理圖像分類任務，並在捕捉局部特徵的同時利用 Transformer 來學習全局關聯。在實際應用中，還可以進一步優化模型結構、調整超參數、進行更多的數據增強等，來進一步提升模型的性能。

---

### 優化建議：
- **數據增強**：可以添加更多的增強操作，如旋轉、亮度調整等，來增強模型的泛化能力。
- **學習率調整**：使用學習率衰減或自適應學習率方法（如 `ReduceLROnPlateau`）來提高訓練效率。
- **模型微調**：對於訓練時間較長的模型，可以進行早停策略來避免過擬合。

這個模型結合了 CNN 和 Transformer 的優勢，能夠在多種圖像分類任務中表現出色。