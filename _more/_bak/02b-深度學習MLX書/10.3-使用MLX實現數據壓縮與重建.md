### 使用 MLX 實現數據壓縮與重建

在這一節中，我們將使用 MLX 框架來實現數據壓縮與重建的流程。這個過程通常涉及到自編碼器（Autoencoder）模型，它可以將數據映射到低維度潛在空間進行壓縮，然後再從這個潛在空間重建原始數據。

#### 1. **自編碼器（Autoencoder）結構**

自編碼器是一種無監督學習模型，通常由三部分組成：

- **編碼器（Encoder）**：將輸入數據壓縮到潛在空間，通常會減少數據的維度。
- **潛在空間（Latent Space）**：是壓縮後的低維度表示。
- **解碼器（Decoder）**：根據潛在空間中的表示重建輸入數據。

自編碼器的目標是最小化重建誤差，即原始數據與重建數據之間的差異。

#### 2. **數據壓縮與重建的數學背景**

假設我們有一組數據 \( X \)，自編碼器將其映射到低維潛在空間 \( Z \)，然後使用解碼器 \( \hat{X} = D(Z) \) 重建出數據。這個過程的數學公式為：

- **編碼**：\( Z = E(X) \)，其中 \( E \) 是編碼器，將數據 \( X \) 映射到潛在空間 \( Z \)。
- **重建**：\( \hat{X} = D(Z) \)，其中 \( D \) 是解碼器，將潛在變數 \( Z \) 重建回原始數據空間。

訓練自編碼器的目標是最小化以下損失函數：

\[
\mathcal{L} = ||X - \hat{X}||^2
\]

這裡，損失函數是原始數據與重建數據之間的均方誤差（MSE）。

#### 3. **使用 MLX 實現數據壓縮與重建**

接下來，我們將使用 MLX 來構建一個簡單的自編碼器，並使用這個模型進行數據壓縮與重建。假設我們使用 MNIST 數據集，這是一個經典的手寫數字數據集，包含 28x28 像素的灰度圖像。

##### 3.1. **定義自編碼器模型**

```python
import mlx
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# 自編碼器模型定義
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        # 編碼器
        self.encoder = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28 * 28, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 32)
        )
        # 解碼器
        self.decoder = nn.Sequential(
            nn.Linear(32, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, 28 * 28),
            nn.Sigmoid(),  # 使用 Sigmoid 激活函數，輸出在 [0, 1] 範圍內
            nn.Unflatten(1, (1, 28, 28))  # 轉換回 28x28 的形狀
        )

    def forward(self, x):
        # 編碼過程
        z = self.encoder(x)
        # 重建過程
        return self.decoder(z)

# 初始化模型
model = Autoencoder()
```

##### 3.2. **數據預處理與加載**

我們使用 PyTorch 的 `DataLoader` 加載 MNIST 數據集並進行預處理：

```python
# 數據轉換：將圖像標準化到 [0, 1] 範圍
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])

# 加載 MNIST 數據集
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
```

##### 3.3. **定義損失函數與優化器**

我們使用均方誤差（MSE）作為損失函數，並使用 Adam 優化器來訓練模型：

```python
# 定義損失函數和優化器
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
```

##### 3.4. **訓練模型**

我們進行訓練，並在每個 epoch 後打印訓練損失：

```python
# 訓練模型
num_epochs = 5

for epoch in range(num_epochs):
    model.train()
    total_loss = 0
    for batch_idx, (data, _) in enumerate(train_loader):
        # 將數據移到 GPU（如果可用）
        data = data.cuda() if torch.cuda.is_available() else data

        # 重置梯度
        optimizer.zero_grad()

        # 前向傳播
        output = model(data)

        # 計算損失
        loss = criterion(output, data)
        total_loss += loss.item()

        # 反向傳播
        loss.backward()

        # 更新參數
        optimizer.step()

    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader)}")
```

##### 3.5. **數據壓縮與重建結果**

訓練完成後，我們可以使用訓練好的模型對一個樣本進行壓縮與重建：

```python
import matplotlib.pyplot as plt

# 隨機選取一個樣本
sample_data, _ = next(iter(train_loader))

# 選擇其中的一個樣本進行顯示
original_image = sample_data[0].numpy().squeeze()

# 使用模型進行重建
model.eval()
with torch.no_grad():
    compressed_image = model(sample_data[0].unsqueeze(0).cuda() if torch.cuda.is_available() else sample_data[0].unsqueeze(0))

# 顯示原始圖像與重建圖像
reconstructed_image = compressed_image.squeeze().cpu().numpy()

# 顯示結果
fig, ax = plt.subplots(1, 2, figsize=(10, 5))
ax[0].imshow(original_image, cmap='gray')
ax[0].set_title('Original Image')
ax[0].axis('off')
ax[1].imshow(reconstructed_image, cmap='gray')
ax[1].set_title('Reconstructed Image')
ax[1].axis('off')
plt.show()
```

這樣，我們就能夠查看原始圖像與通過自編碼器重建的圖像，並觀察數據壓縮的效果。

#### 4. **總結**

在這一節中，我們使用了 MLX 來實現數據壓縮與重建，這主要通過自編碼器模型來完成。我們展示了如何將數據映射到潛在空間進行壓縮，並從潛在空間重建出原始數據。這樣的技術可以應用於圖像壓縮、降噪以及數據降維等多個領域。