### 自編碼器的結構與應用

自編碼器（Autoencoder，簡稱 AE）是一種神經網絡架構，旨在將輸入數據壓縮為較低維度的隱藏表示（編碼），並將其解碼回原始數據（重建）。自編碼器在無監督學習中有廣泛的應用，特別是數據降維、特徵學習、去噪、生成模型等領域。

#### 1. **自編碼器的基本結構**

自編碼器的結構通常包括三個主要部分：

- **編碼器（Encoder）**：負責將輸入數據映射到一個低維度的隱藏空間，這部分通常包含一系列的神經網絡層（如全連接層、卷積層等），最終生成隱藏表示（通常稱為編碼）。
  
- **隱藏表示（Latent Representation）**：這是數據經過編碼器後的低維度表示，捕捉了輸入數據的最重要特徵。這個過程本質上是進行特徵學習。
  
- **解碼器（Decoder）**：將隱藏表示映射回原始數據空間。解碼器將低維度的編碼恢復為與原始數據相似的數據，通常會使用與編碼器對稱的神經網絡結構。

**自編碼器的目標**是使輸入數據和重建數據之間的差異最小化，這通常通過最小化重建誤差來實現。

#### 2. **自編碼器的數學原理**

假設輸入數據為 \( X \)，編碼器和解碼器分別為 \( f \) 和 \( g \)，則自編碼器的目標是最小化重建誤差：

\[
\mathcal{L}(X) = \| X - g(f(X)) \|_2^2
\]

其中 \( \mathcal{L}(X) \) 表示重建誤差，通常選擇歐式距離（L2 範數）來度量原始數據 \( X \) 和重建數據之間的差距。

#### 3. **自編碼器的應用**

自編碼器在多個領域中有著重要的應用，以下是一些常見的應用場景：

- **數據降維**：自編碼器通過學習數據的低維表示來達到降維的目的，這與傳統的主成分分析（PCA）類似，但能夠學習更複雜的非線性映射。
  
- **特徵學習**：自編碼器能夠從數據中自動學習到特徵，並且這些特徵可以用於其他機器學習任務，例如分類、聚類等。

- **去噪自編碼器（Denoising Autoencoder）**：通過將部分輸入數據隨機污染（如加入噪聲），讓自編碼器學會去除噪聲並重建清晰的數據，這樣可以提高模型的魯棒性。

- **生成模型**：自編碼器中的隱藏表示有時可以用作生成模型的一部分，尤其是變分自編碼器（VAE）可以用於生成新數據樣本。

- **異常檢測**：由於自編碼器擅長學習數據的正常模式，因此它們也可以用來識別異常數據。當自編碼器無法良好重建某些數據時，這些數據可能是異常的。

#### 4. **自編碼器的變體**

除了基本的自編碼器外，還有一些變體，它們在特定的應用中更加有效：

- **去噪自編碼器（Denoising Autoencoder, DAE）**：在輸入數據中添加噪聲，然後讓自編碼器學習從噪聲數據中恢復乾淨的數據。

- **變分自編碼器（Variational Autoencoder, VAE）**：VAE 是一種生成模型，它將自編碼器與概率模型相結合。VAE 在學習隱藏表示時，強制隱藏表示遵循某些分佈（如高斯分佈），這使得其在生成新數據時更加靈活。

- **卷積自編碼器（Convolutional Autoencoder）**：使用卷積神經網絡（CNN）作為編碼器和解碼器，特別適用於圖像數據，能夠更有效地提取圖像特徵。

#### 5. **使用 MLX 實現自編碼器**

這裡展示如何使用 MLX 實現一個簡單的自編碼器。

```python
import mlx
import mlx.nn as nn
import mlx.optim as optim
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# 定義自編碼器模型
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(784, 512),  # 784 -> 512
            nn.ReLU(),
            nn.Linear(512, 256),  # 512 -> 256
            nn.ReLU(),
            nn.Linear(256, 64)    # 256 -> 64
        )
        self.decoder = nn.Sequential(
            nn.Linear(64, 256),  # 64 -> 256
            nn.ReLU(),
            nn.Linear(256, 512),  # 256 -> 512
            nn.ReLU(),
            nn.Linear(512, 784),  # 512 -> 784
            nn.Sigmoid()           # 784 -> 784 (output is in range [0,1])
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# 加載 MNIST 數據集
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
data_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

# 初始化模型、損失函數和優化器
model = Autoencoder()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 訓練模型
epochs = 10
for epoch in range(epochs):
    for data in data_loader:
        images, _ = data
        images = images.view(-1, 784)  # 展開為 784 維向量
        optimizer.zero_grad()

        # 前向傳播
        output = model(images)
        
        # 計算損失
        loss = criterion(output, images)
        
        # 反向傳播
        loss.backward()
        optimizer.step()

    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')

# 使用訓練好的自編碼器來重建圖像
import matplotlib.pyplot as plt

# 查看重建圖像
test_images, _ = next(iter(data_loader))
test_images = test_images.view(-1, 784)
reconstructed = model(test_images)

# 顯示原圖與重建圖像
fig, axes = plt.subplots(2, 8, figsize=(10, 4))
for i in range(8):
    axes[0, i].imshow(test_images[i].view(28, 28).detach().numpy(), cmap='gray')
    axes[1, i].imshow(reconstructed[i].view(28, 28).detach().numpy(), cmap='gray')
    axes[0, i].axis('off')
    axes[1, i].axis('off')
plt.show()
```

#### 6. **結語**

自編碼器是一種強大的無監督學習工具，能夠有效地進行數據降維、特徵學習及生成模型等多種任務。在 MLX 框架下實現自編碼器，簡單且高效，可以應用於各種數據處理場景。